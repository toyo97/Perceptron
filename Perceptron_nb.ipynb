{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "def multi_cat_transform(X):\n",
    "    columns = X.columns.values\n",
    "    for col in columns:\n",
    "        dummies = X[col].str.get_dummies(sep='; ')\n",
    "        dummies.columns = [col+'_'+c for c in dummies.columns]\n",
    "        X = pd.concat([X, dummies], axis=1)\n",
    "    return X.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Read CSV file and import in Pandas DataFrame\n",
    "data_file = open('data/survey_results_public.csv')\n",
    "df = pd.read_csv(data_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early manipulation of DF:\n",
    "# - remove ExpectedSalary col (not relevant)\n",
    "# - remove rows without salary value\n",
    "# - extract target (Salary)\n",
    "df.drop(['ExpectedSalary'], axis=1, inplace=True)\n",
    "df = df[pd.notnull(df['Salary'])]\n",
    "salary_col = df.pop('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize target using median threshold (0 for values lt median, 1 for values gt median)\n",
    "median_salary = salary_col.median()\n",
    "y = np.array(salary_col.values >= median_salary, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate train-set and test-set with test size fixed above\n",
    "df_train, df_test, y_train, y_test = train_test_split(df,\n",
    "                                                      y,\n",
    "                                                      test_size=TEST_SIZE,\n",
    "                                                      random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (columns) in numeric-value f., category f. and multiple category f.\n",
    "# Create numpy boolean index array\n",
    "# 'O' stands for Object, while numeric values are floats or ints\n",
    "kinds = np.array([dt.kind for dt in df.dtypes])\n",
    "is_num = kinds != 'O'\n",
    "\n",
    "all_cols = df.columns.values\n",
    "\n",
    "num_cols, cat_cols = all_cols[is_num], all_cols[~is_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High unique values count indicates multiple category feature (to be separated) - plus exceptions\n",
    "# Threshold (200) found empirically from dataset overview using the following procedure:\n",
    "# Detail on number of unique values per column\n",
    "#\n",
    "# unique_features = df.nunique().sort_values(ascending=False)\n",
    "# unique_features[:40]\n",
    "# df[unique_features.index[9:27]]\n",
    "# df['VersionControl'].value_counts()\n",
    "#\n",
    "# same for the three exceptions\n",
    "multi_cat_cols = [c for c in df[cat_cols] if df[c].nunique() >= 200] + ['Race', 'StackOverflowDevices', 'Gender']\n",
    "single_cat_cols = [c for c in cat_cols if c not in multi_cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of scikit-learn Pipelines and ColumnTransformer to operate dataset transformation\n",
    "# Numeric values must be imputed where missing (replacing NaN with median value) and scaled around 0.\n",
    "num_si_step = ('si', SimpleImputer(missing_values=np.nan, strategy='median'))\n",
    "num_ss_step = ('ss', StandardScaler())\n",
    "num_steps = [num_si_step, num_ss_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category values also must be imputed where missing (with NotAnswered constant category) and encoded\n",
    "# OneHotEncoder creates k columns of ones and zero where k is the number of unique categories\n",
    "cat_si_step = ('si', SimpleImputer(strategy='constant', fill_value='NA'))\n",
    "cat_ohe_step = ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "cat_steps = [cat_si_step, cat_ohe_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some features are groups of different categories, they are split and encoded using a FunctionTransformer which\n",
    "# calls the custom function defined at the top of the file\n",
    "multi_cat_step = ('mce', FunctionTransformer(multi_cat_transform, validate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline(num_steps)\n",
    "cat_pipe = Pipeline(cat_steps)\n",
    "multi_cat_pipe = Pipeline([multi_cat_step])\n",
    "\n",
    "multi_cat_transformer = ('multi_cat', multi_cat_pipe, multi_cat_cols)\n",
    "num_transformer = ('num', num_pipe, num_cols)\n",
    "cat_transformer = ('cat', cat_pipe, single_cat_cols)\n",
    "transformers = [multi_cat_transformer, num_transformer, cat_transformer]\n",
    "\n",
    "ct = ColumnTransformer(transformers=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train_samples, n_train_features: (10312, 1217)\n"
     ]
    }
   ],
   "source": [
    "# Use the transformer to obtain a numeric numpy matrix\n",
    "X_train = ct.fit_transform(df_train)\n",
    "\n",
    "print('n_train_samples, n_train_features: {}'.format(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "10-fold cross validation scores: [0.84011628 0.78682171 0.85354025 0.83511154 0.84675073 0.83414161\n",
      " 0.85451018 0.83899127 0.8128031  0.83802134]\n",
      "Mean: 0.8340808013594087\n"
     ]
    }
   ],
   "source": [
    "# Select the Perceptron linear model from scikit-learn library (with some parameters)\n",
    "clf = Perceptron(max_iter=40, tol=1e-3)\n",
    "\n",
    "print('\\n10-FOLD CROSS VALIDATION')\n",
    "# Use cross_val_score function from sklearn to get accuracy scores out of a 10-fold cross validation\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=k_fold)\n",
    "print('10-fold cross validation scores: {}'.format(scores))\n",
    "print('Mean: {}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRID SEARCH\n",
      "Best params: {'max_iter': 20, 'tol': 0.01}\n",
      "Grid search best score: 0.8376648564778898\n",
      "   param_tol param_max_iter  mean_test_score  std_test_score  mean_fit_time\n",
      "0       0.01              5         0.819628        0.040127       0.181072\n",
      "1      0.001              5         0.819628        0.040127       0.195049\n",
      "2     0.0001              5         0.819628        0.040127       0.185915\n",
      "3      1e-05              5         0.819628        0.040127       0.185883\n",
      "4       0.01             10         0.820694        0.031784       0.251086\n",
      "5      0.001             10         0.820694        0.031784       0.248963\n",
      "6     0.0001             10         0.820694        0.031784       0.251119\n",
      "7      1e-05             10         0.820694        0.031784       0.258116\n",
      "8       0.01             15         0.816137        0.025107       0.325989\n",
      "9      0.001             15         0.816137        0.025107       0.317162\n",
      "10    0.0001             15         0.816137        0.025107       0.326668\n",
      "11     1e-05             15         0.816137        0.025107       0.335117\n",
      "12      0.01             20         0.837665        0.019978       0.371979\n",
      "13     0.001             20         0.836501        0.019114       0.367081\n",
      "14    0.0001             20         0.836501        0.019114       0.376678\n",
      "15     1e-05             20         0.836501        0.019114       0.375630\n",
      "16      0.01             50         0.834465        0.019713       0.409196\n",
      "17     0.001             50         0.834077        0.019291       0.434414\n",
      "18    0.0001             50         0.834077        0.019291       0.441124\n",
      "19     1e-05             50         0.834077        0.019291       0.444297\n"
     ]
    }
   ],
   "source": [
    "print('\\nGRID SEARCH')\n",
    "# Perceptron hyperparameters tuning using GridSearch with 10-fold cv\n",
    "tol_params = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "max_iter_params = [5, 10, 15, 20, 50]\n",
    "\n",
    "param_grid = {\n",
    "    'tol': tol_params,\n",
    "    'max_iter': max_iter_params\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(Perceptron(), param_grid, scoring='accuracy', cv=k_fold)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print('Best params: {}'.format(best_params))\n",
    "print('Grid search best score: {}'.format(grid_search.best_score_))\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results[['param_tol', 'param_max_iter', 'mean_test_score', 'std_test_score', 'mean_fit_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPREDICTION TEST')\n",
    "# Use best parameters to predict salary in the test set\n",
    "X_test = ct.transform(df_test)\n",
    "best_clf = Perceptron(tol=best_params['tol'], max_iter=best_params['max_iter'])\n",
    "best_clf.fit(X_train, y_train)\n",
    "print('Score on test set: {}'.format(best_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nLEARNING CURVE')\n",
    "# Plot the learning curve\n",
    "X = ct.fit_transform(df)\n",
    "\n",
    "train_sizes = np.linspace(.1, 1.0, 5)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(best_clf, X, y, cv=k_fold, n_jobs=4, train_sizes=train_sizes)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Learning Curves (Perceptron)')\n",
    "plt.ylim((0.7, 1.01))\n",
    "plt.xlabel('Training samples')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.grid()\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std,\n",
    "                 alpha=0.1, color='r')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std,\n",
    "                 alpha=0.1, color='g')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='r',\n",
    "         label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='g',\n",
    "         label='Cross-validation score')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
